\documentclass{acm_proc_article-sp}
%\usepackage{graphicx}
%\usepackage[pdftex]{graphicx}
%\usepackage{subfig}
%\DeclareGraphicsExtensions{.pdf,.png,.jpg}
 \makeatletter
 \let\@copyrightspace\relax
 \makeatother

\begin{document}

\title{VideoSearch: a Lucene Powered Desktop Video Search System}



\numberofauthors{2} 
%
\author{
\alignauthor
Matthew Beldyk\\
       \affaddr{University of Colorado}\\
       \affaddr{CSCI 5722}\\
       \affaddr{Boulder, Colorado}\\
       \email{beldyk@colorado.edu}
\alignauthor
Michael Brunel\\
       \affaddr{University of Colorado}\\
       \affaddr{CSCI 5722}\\
       \affaddr{Boulder, Colorado}\\
       \email{leachim.bulwark@gmail.com}
}
\maketitle
\begin{abstract}

ABSTRACT HERE
\end{abstract}

\section{Introduction}
It comes as no surprise that as the cost of storage media decrease, the rate at which we store data increases. This increase in storage has outpaced our ability to catalogue and organize this data properly. As such, we are left with huge volumes of media that is increasingly becoming harder to navigate to find something that we are looking for. However, even when things are kept in a modicum of control, there is still the issue of finding something that you want to watch. Say you are in the mood for some espionage, a few titles may come to mind immediately but there is very likely a large number of items in your collection that also qualify as espionage. Without an easy way to determine which videos are related, you are left with a giant collection of videos that will go largely un-viewed.

    There are many ways that people organize and catalogue their data to help them keep it all straight. But even the best catalogue scheme does not allow for the fine grained approach that is necessary when you are looking for a specific type of show to watch. To truly be able to navigate a large collection, one must be able to search the collection for items of relevance. To this end we present VideoSearch.  
\section{Body}
\subsection{The Current State of the Art}

    There are many systems that offer video search.  For example. video.google.com allows users to search metadata about specific videos.  Google video does pull in extra metadata from the website where a video is posted, but it does not read external databases of material and attempt to associate that information with individual videos in the same way that VideoSearch does.  There are also a number of multimedia jukebox applications that index a file system in an attempt to provide a better user experience than simple browing directories. XBMC will even associate tvdb metadata with files on the user’s system\cite{goodwin2010appliance}, but XBMC does not include an TF/IDF index into this material; it is only used to enhance the end result of what is displayed to the user once they have found a file of interest. There are also a number of other multimedia content playing applications such as MythTv, Boxee, iTunes, and Freevo.\cite{schopman2010notube}

    Smeaton’s paper from 2007 describes the state of the art in video search. \cite{smeaton2007techniques} For example, Google Video search uses closed captioning information for video streams as part of their feature set, and so does Fischlar-news \cite{lee2006user} but there have been a number of new emerging players in this venue in the past couple years.  The website hulu.com provides numerous television shows available for streaming online and offers a basic search engine into their online streaming videos \cite{patent:20100287474} Hulu also provides relevant advertisements based on the textual information around their embedded videos.

    As VideoSearch incorporates many features from desktop search, it is prudent to mention other similar systems.  The Beagle search engine is a system that runs on a user’s personal computer to index and allow textual search of their various files.  \cite{brunkhorst2006beagle++}  Beagle will process the local filesystem to find documents to index while the computer is up, and will occasionally search again to find any new or deleted files.  Recent versions of Apple OSX include a piece of software called Spotlight.\cite{applex} Spotlight is also a desktop search system.


\subsection{The Architexture of VideoSearch}
    To address the problems involved with large multimedia collections, we have created a system entitled VideoSearch.  VideoSearch is a framework that augments the creation of an index of a collection of televsion shows on a user’s harddrive, by pulling in ancillary metadata about this multimedia from various online sources.  VideoSearch is based around the Java Lucene search framework.  The first stage in VideoSearch is the collection of unique multimedia URLs for the collection to index. Currently the code parses a filesystem, but the code is arcetextured in such a way to make it simple to drop in any other sort of indexing system; a webspider would be an obvious replacement.  

The next stage is to parse each of these found items into a more machine readable format.  Currently, the system has a very simple DSL that describes how filenames are formatted.  We decided on an easily format to parse and write, because it would encourage the user to tweak these simple lines to their personal collection.  \cite{favorite RE book} We found that only a couple regular expression lines would suffice to parse the vast majority of data in our collection, but the last few that our system could not parse would require manual intervention to correctly identify the files.  As with the initial indexing, we wrote VideoSearch so that swapping in a replacement for the DSL system would be trivial.  VideoSearch’s DSL system only looks at the actual file name; it ignores the rest of the file url structure.  Users will often sort common shows into the same folder, and in the future, it might make sense to look at the entire structure, or even to look at how multimedia items have been tokenized in the same directory.
%FIXME latex regular expression line here

Once the tokenization stage is complete, ancillary metadata must be pulled into the system.  Initially, VideoSearch only pulls in metadata from thetvdb.com or tvdb for short.  Tvdb has a REST API for programmer use. \cite{tvdb} There is also a Java API that wraps the REST API to make it even easier to mine information from their online database of user created information.  To use metadata from tvdb, there are a couple steps.  First, a list of unique series names must be compiled from all the tokenized files.  We wish to avoid making multiple calls for the same series to avoid overwhelming the tvdb website. Then for each series we identified, a query must be made to tvdb with the series name; tvdb will then respond with a list of several best matches on this name.  For simplicity sake, we choose the first match retrieved, which generally apears to be the best one. In future versions of this system, the user should be able to select the best series match.  These returned series also have a series id associated with them.  The next step is to query tvdb with this series id to retrieve an object with all of the information associated with the series.

Once we have the information associated with each series, we need to associated this series information with the initial files.  VideoSearch has a Lucene index that must be filled with this information.  We treat each individual multimedia file as a document and the tokenized parts of the document as fields for indexing.  VideoSearch also includes the full description of the series as a field with each file, and if there is a description for that specific episode, it is also included.  This is repeated for every single file to be indexed.

After the full index is created, which only takes a couple minutes for the 3000+ files in our test collection, VideoSearch is available for searching.  Currently, VideoSearch only has a command line interface working; a web based frontend was in the works, but was delayed by the increased workload at the end of the semester.  There are two routes to go with VideoSearch right now: complete the web GUI or tie VideoSearch into another multimedia collection system.


\section{Results}
    By utilizing as much meta-data as possible to classify each video we are striving to provide a complete account of what a video truly represents. When you make that search for espionage, you will likely get the staples of James Bond, The Bourne Identity, and many others, but VideoSearch will also find the WWII documentary on infiltrating the 3rd Reich that you forgot that you downloaded.

    By incorporating user reviews and descriptions into the indexing algorithm, we can provide a better user driver experience into the mix. We have all seen cases where the box cover description of the video is lack luster at best, completely misleading at worst. By utilizing user based data, we can hopefully counteract this problem and provide a better result that more accurately represents the true nature of the video.

   


\subsection{Analysis}

It is difficult to evaluate the effectiveness of VideoSearch. The smaller parts of the system can be evaluated to a certain degree; for example, the filename tokenization code can be evaluated for a set of test cases, but it would be exorbitantly expensive to test for the entirety of our test set.  There is also no “gold standard” for what videos should be returned for various topics.  There were, in fact, many surprises found while testing; a search for “travel” would return various travel shows, but would also return “Doctor Who.”  “Doctor Who” while not what one would normally consider a travel show, is absolutely about a traveler, so it is unknown how this result should be evaluated.

In the end, the true evaluation of this system would need to be several user tests, where they’ve indexed their collection, and would use the system over a period of time noting whether they were finding what they expected, had a pleasant surprise of something they had completely forgotten, or not finding what they wanted.  Once can imagine the case where a user remembered they had some show about “crystal skulls” or some other topic of interest, they would enter that as a search term, and they might or might not find the documentaries or movies they desired.


\section{Conclusions}
    As with all search applications we have been faced with the problem of ambiguity in search terms. What do you return for a search about “travel”, clearly you include the travel channels special on backpacking in the Andes, but what about “A culinary tour of Asia” or “Doctor Who” the time travelling doctor. Coupled with this is the lesser issue of how you handle series that have more than one, but not necessarily all, of their episodes related to the query?

    Possibly the largest hurtle to getting a system of this kind up and running is parsing the large volumes of data. There is no universal standard, there are a few guidelines that are followed but this only accounted for about half of what we indexed. This has created a monumental challenge in determining what each file actually is. We were able to get 90\% of the files to parse with a small set of around 10 rules, however the remaining 10\% were all going to have to be custom tailored. This is all on a collection of only a few thousand files, largely from the same resource.

    Having finally parsed the files, gathering the information about each file also proved difficult. Wanting to only index information for content that we have already, we had to search the information sources for matches to our parsed data. For some things like “Doctor Who” this was very easy, seeing as each episode has at least a full page article detailing everything about the episode. However, for many shows/movies there was limited to no information about them at the site we utilized. Furthermore, there was the issue of abbreviations, tvdb was unable to determine the proper expansion for abbreviations. These issues can largely be curtailed by including more information sources, potentially even using one to help search another. However, this expansion of sources ran afoul when we discovered that many sites dislike automated tools interacting with them.

    In the end, we have come to the conclusion that our design would be best suited as part of a larger project (xmbc, windows media center,etc...). Not only do we gain access to the work that has already been done by these projects in the area of parsing, and potentially data collection. But we also remove the need for the user to install another application to handle their growing media collection. When attempting to handle the ever growing size of a media collection  the last thing the user needs is to install yet another program. 
\bibliographystyle{abbrv}
\bibliography{ir_paper}


\end{document}